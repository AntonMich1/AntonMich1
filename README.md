- üëã Hi, I‚Äôm @AntonMicheal
- üëÄ I‚Äôm interested in biology, mathematics, sport, finance and coding
- üå± Predictive modelling & machine learning approaches...
- üíûÔ∏è I‚Äôm looking to collaborate on ML projects
- üì´ Reach me antonilango@hotmail.com
- üòÑ Pronouns: JumpTheMouse
- ‚ö° Fun fact: Playing Volleyball, Biking, Solving puzzles

<!---
AntonMich1/AntonMich1 is a ‚ú® special ‚ú® repository because its `README.md` (this file) appears on your GitHub profile.
You can click the Preview link to take a look at your changes.
--->
Projects
This section is a portfolio of Machine Learning projects with Python and various visualization and analysis tools. Most of these projects were carried out within the framework of IBM Data science certifications. They are presented with Jupyter Notebooks. I updated some projects by incorporating more in-depth data analysis, better graphs, advanced ML techniques.
* SpaceX Falcon 9 First Stage Landing Prediction
  
https://github.com/AntonMich1/testrepo/tree/main
In this project, we predict if the Falcon 9 first stage will land successfully. Project includes: SpaceX data collection, Data Wrangling, Webscraping, EDA with SQL Queries & Data visualization, SpaceX Launch Records Dashboard, Launch Sites Locations Analysis with Folium, Machine Learning classification with optimization of hyperparameters and selection of best model: KNN, Decision Tree, SVM, Logistic Regression.

Mathematics of Machine Learning. Most of these projects were carried out within the framework of Imperial College Online certifications. They are presented with Jupyter Notebooks. I updated some projects by incorporating more and more interesting questions
https://github.com/AntonMich1/Mathematics_MachineLearning

Ongoing Projects

A: Reinforcement Learning- Temporal difference (TD) Regularized Actor-Critic model for Active Avoidance Learning:
Here, I am using parameters we used to train mice in cue-signaled active avoidance(AA) learning and fed the real learning data from 100 trials of AA learning into an Actor-critic model framework. An actor-critic model, with separate learning rates for action selection (in the actor) and state evaluation (in the critic), was applied to individual mice during avoidance acquisition. Latent parameters, such as learning rate and the subjective reinforcement value of foot shock, were extracted and compared across. To enhance stability, I integrated Temporal Difference (TD) learning, which is particularly effective in handling delayed rewards and punishments‚Äîkey factors in avoidance behaviors. The TD error aligns with biological mechanisms like dopamine signaling, making it a plausible model for understanding how animals learn to avoid threats. Additionally, the regularization term ensures stable and efficient learning, even in uncertain and complex environments.  I am currently investigating whether the TD regulated Actor-Critic RL model represents and successfully predicts avoidance behavior.

I will provide updates as the project progresses.



